{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Imports f√ºr alle Notebooks\n",
    "\n",
    "!pip3 install tira ir-datasets python-terrier\n",
    "\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n",
    "\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erstellen von costum Retrieval Systemen\n",
    "\n",
    "def create_index(documents, stopwords):\n",
    "    # Stemmer has been added \n",
    "    indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, meta={'docno': 100, 'text': 20480}, stemmer='EnglishSnowballStemmer', stopwords=stopwords)\n",
    "    # indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, meta={'docno': 100, 'text': 20480}, stemmer='PorterStemmer', stopwords=stopwords)\n",
    "    # indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, meta={'docno': 100, 'text': 20480}, stemmer='WeakPorterStemmer', stopwords=stopwords)\n",
    "    # # indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, meta={'docno': 100, 'text': 20480}, stemmer='StemmerTermPipeline', stopwords=stopwords)\n",
    "    \n",
    "    index_ref = indexer.index(documents)\n",
    "    return pt.IndexFactory.of(index_ref)\n",
    "\n",
    "def read_text_file_to_array(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            # Remove newline characters and convert to integers\n",
    "            array = [(line.strip()) for line in lines]\n",
    "            return array\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "        return None\n",
    "\n",
    "# Read txt file and convert it to an array\n",
    "file_path = \"../terrier-stopwordslist.txt\"\n",
    "\n",
    "stopwords = read_text_file_to_array(file_path)\n",
    "\n",
    "\n",
    "costum_index = create_index(pt_dataset.get_corpus_iter(), stopwords)\n",
    "\n",
    "XSqrA_M\t = pt.BatchRetrieve(index, wmodel=\"XSqrA_M\")\n",
    "XSqrA_M_costum\t = pt.BatchRetrieve(costum_index, wmodel=\"XSqrA_M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "\n",
    "pt.Experiment(\n",
    "    [XSqrA_M, XSqrA_M_costum],\n",
    "    pt_dataset.get_topics(),\n",
    "    pt_dataset.get_qrels(),\n",
    "    [\"ndcg_cut.10\", \"recip_rank\", \"recall_100\", \"P_10\"],\n",
    "    names = [\"XSqrA_M\", \"XSqrA_M_costum\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
