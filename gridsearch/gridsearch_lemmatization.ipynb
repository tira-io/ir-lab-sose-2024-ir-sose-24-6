{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Imports f端r alle Notebooks\n",
    "\n",
    "!pip3 install tira ir-datasets python-terrier nltk scikit-learn spacy\n",
    "\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n",
    "\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der NLTK Ressourcen\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Laden der SpaCy-Ressourcen\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Laden des SpaCy-Modells\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode um Beschreibung des POS-Tags zu bekommen f端r den NLTK Lemmatizer\n",
    "def get_wordnet_pos_nltk(treebank_tag):\n",
    "    \"\"\"Konvertiert POS-Tag in ein Format, das vom WordNet-Lemmatizer unterst端tzt wird.\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# Funktion um den Text zu lemmatizen f端r NLTK Lemmatizer\n",
    "def lemmatize_text_nltk(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos_nltk(tag)) for token, tag in pos_tags]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Definition der Funktion zur Lemmatization eines Textes mit SpaCy\n",
    "def lemmatize_text_spacy(text):\n",
    "    \"\"\"Lemmatiziert den gegebenen Text mit SpaCy.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "def preprocess_documents(documents, method):\n",
    "    if method == 'nltk':\n",
    "        lemmatize_text = lemmatize_text_nltk\n",
    "    elif method == 'spacy':\n",
    "        lemmatize_text = lemmatize_text_spacy\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method specified. Use 'nltk' or 'spacy'.\")\n",
    "\n",
    "    for doc in documents:\n",
    "        doc['text'] = lemmatize_text(doc['text'])\n",
    "        yield doc\n",
    "\n",
    "#Funktion um eigene Indecies zu erstellen\n",
    "def create_index(base_path, documents, stopwords, stemmer):\n",
    "    # Generate a unique identifier based on current timestamp\n",
    "    unique_id = hashlib.sha1(str(time.time()).encode('utf-8')).hexdigest()[:8]\n",
    "    \n",
    "    # Construct the unique path using base_path and unique_id\n",
    "    index_path = os.path.join(base_path, f\"index_{unique_id}/\")\n",
    "    \n",
    "    indexer = pt.IterDictIndexer(index_path, overwrite=True, meta={'docno': 100, 'text': 20480}, stopwords=stopwords, stemmer=stemmer)\n",
    "    index_ref = indexer.index(documents)\n",
    "    return pt.IndexFactory.of(index_ref)\n",
    "\n",
    "#Funktion um aus einem txt-file eine Python Liste zu machen\n",
    "def read_text_file_to_array(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            # Remove newline characters and convert to integers\n",
    "            array = [(line.strip()) for line in lines]\n",
    "            return array\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom stopword lists\n",
    "terrier_custom_stopwords = read_text_file_to_array('../terrier-custom.txt')\n",
    "chatgpt_stopwords = read_text_file_to_array('../chatgpt-stopwordlist.txt')\n",
    "\n",
    "base_path = '/workspaces/ir-lab-sose-2024-ir-sose-24-6/gridsearch/var/tmp/'\n",
    "\n",
    "# Naming: [Stemmer/Lemmatizer]_[Type]__[StopwordList]\n",
    "indices = {\n",
    "    \"L_N_T\": create_index(base_path, preprocess_documents(pt_dataset.get_corpus_iter(), 'nltk'), terrier_custom_stopwords, 'NoOp'),\n",
    "    \"L_N_C\": create_index(base_path, preprocess_documents(pt_dataset.get_corpus_iter(), 'nltk'), chatgpt_stopwords, 'NoOp'),\n",
    "    \"L_N_N\": create_index(base_path, preprocess_documents(pt_dataset.get_corpus_iter(), 'nltk'), [], 'NoOp'),\n",
    "    \"L_S_T\": create_index(base_path, preprocess_documents(pt_dataset.get_corpus_iter(), 'spacy'), terrier_custom_stopwords, 'NoOp'),\n",
    "    \"L_S_C\": create_index(base_path, preprocess_documents(pt_dataset.get_corpus_iter(), 'spacy'), chatgpt_stopwords, 'NoOp'),\n",
    "    \"L_S_N\": create_index(base_path, preprocess_documents(pt_dataset.get_corpus_iter(), 'spacy'), [], 'NoOp')\n",
    "}\n",
    "\n",
    "retrieval_models_nltk = {\n",
    "    \"L_N_T_XSqrA_M\": pt.BatchRetrieve(indices[\"L_N_T\"], wmodel=\"XSqrA_M\"),\n",
    "    \"L_N_T_BM25\": pt.BatchRetrieve(indices[\"L_N_T\"], wmodel=\"BM25\"),\n",
    "    \"L_N_T_DPH\": pt.BatchRetrieve(indices[\"L_N_T\"], wmodel=\"DPH\"),\n",
    "    \n",
    "    \"L_N_C_XSqrA_M\": pt.BatchRetrieve(indices[\"L_N_C\"], wmodel=\"XSqrA_M\"),\n",
    "    \"L_N_C_BM25\": pt.BatchRetrieve(indices[\"L_N_C\"], wmodel=\"BM25\"),\n",
    "    \"L_N_C_DPH\": pt.BatchRetrieve(indices[\"L_N_C\"], wmodel=\"DPH\"),\n",
    "    \n",
    "    \"L_N_N_XSqrA_M\": pt.BatchRetrieve(indices[\"L_N_N\"], wmodel=\"XSqrA_M\"),\n",
    "    \"L_N_N_BM25\": pt.BatchRetrieve(indices[\"L_N_N\"], wmodel=\"BM25\"),\n",
    "    \"L_N_N_DPH\": pt.BatchRetrieve(indices[\"L_N_N\"], wmodel=\"DPH\"),\n",
    "}\n",
    "\n",
    "retrieval_models_spacy = {\n",
    "    \"L_S_T_XSqrA_M\": pt.BatchRetrieve(indices[\"L_S_T\"], wmodel=\"XSqrA_M\"),\n",
    "    \"L_S_T_BM25\": pt.BatchRetrieve(indices[\"L_S_T\"], wmodel=\"BM25\"),\n",
    "    \"L_S_T_DPH\": pt.BatchRetrieve(indices[\"L_S_T\"], wmodel=\"DPH\"),\n",
    "    \n",
    "    \"L_S_C_XSqrA_M\": pt.BatchRetrieve(indices[\"L_S_C\"], wmodel=\"XSqrA_M\"),\n",
    "    \"L_S_C_BM25\": pt.BatchRetrieve(indices[\"L_S_C\"], wmodel=\"BM25\"),\n",
    "    \"L_S_C_DPH\": pt.BatchRetrieve(indices[\"L_S_C\"], wmodel=\"DPH\"),\n",
    "    \n",
    "    \"L_S_N_XSqrA_M\": pt.BatchRetrieve(indices[\"L_S_N\"], wmodel=\"XSqrA_M\"),\n",
    "    \"L_S_N_BM25\": pt.BatchRetrieve(indices[\"L_S_N\"], wmodel=\"BM25\"),\n",
    "    \"L_S_N_DPH\": pt.BatchRetrieve(indices[\"L_S_N\"], wmodel=\"DPH\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple query fields available: ('text', 'title', 'query', 'description', 'narrative'). To use with pyterrier, provide variant or modify dataframe to add query column.\n",
      "There are multiple query fields available: ('text', 'title', 'query', 'description', 'narrative'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    }
   ],
   "source": [
    "# Erhalten der Topics und Lemmatisierung der Queries\n",
    "topics_nltk = pt_dataset.get_topics()\n",
    "topics_nltk['query'] = topics_nltk['query'].apply(lemmatize_text_nltk)\n",
    "topics_spacy= pt_dataset.get_topics()\n",
    "topics_spacy['query'] = topics_spacy['query'].apply(lemmatize_text_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>recall_100</th>\n",
       "      <th>P_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L_N_T_XSqrA_M</td>\n",
       "      <td>0.399378</td>\n",
       "      <td>0.604003</td>\n",
       "      <td>0.536173</td>\n",
       "      <td>0.348529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L_N_T_BM25</td>\n",
       "      <td>0.333125</td>\n",
       "      <td>0.565849</td>\n",
       "      <td>0.516693</td>\n",
       "      <td>0.292647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L_N_T_DPH</td>\n",
       "      <td>0.383537</td>\n",
       "      <td>0.601354</td>\n",
       "      <td>0.526972</td>\n",
       "      <td>0.330882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L_N_C_XSqrA_M</td>\n",
       "      <td>0.392602</td>\n",
       "      <td>0.645102</td>\n",
       "      <td>0.536410</td>\n",
       "      <td>0.332353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_N_C_BM25</td>\n",
       "      <td>0.315186</td>\n",
       "      <td>0.568439</td>\n",
       "      <td>0.516743</td>\n",
       "      <td>0.267647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L_N_C_DPH</td>\n",
       "      <td>0.378403</td>\n",
       "      <td>0.625610</td>\n",
       "      <td>0.524916</td>\n",
       "      <td>0.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L_N_N_XSqrA_M</td>\n",
       "      <td>0.388101</td>\n",
       "      <td>0.681389</td>\n",
       "      <td>0.522145</td>\n",
       "      <td>0.326471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L_N_N_BM25</td>\n",
       "      <td>0.304109</td>\n",
       "      <td>0.550845</td>\n",
       "      <td>0.499112</td>\n",
       "      <td>0.263235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L_N_N_DPH</td>\n",
       "      <td>0.358759</td>\n",
       "      <td>0.616519</td>\n",
       "      <td>0.514664</td>\n",
       "      <td>0.304412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  ndcg_cut.10  recip_rank  recall_100      P_10\n",
       "0  L_N_T_XSqrA_M     0.399378    0.604003    0.536173  0.348529\n",
       "1     L_N_T_BM25     0.333125    0.565849    0.516693  0.292647\n",
       "2      L_N_T_DPH     0.383537    0.601354    0.526972  0.330882\n",
       "3  L_N_C_XSqrA_M     0.392602    0.645102    0.536410  0.332353\n",
       "4     L_N_C_BM25     0.315186    0.568439    0.516743  0.267647\n",
       "5      L_N_C_DPH     0.378403    0.625610    0.524916  0.323529\n",
       "6  L_N_N_XSqrA_M     0.388101    0.681389    0.522145  0.326471\n",
       "7     L_N_N_BM25     0.304109    0.550845    0.499112  0.263235\n",
       "8      L_N_N_DPH     0.358759    0.616519    0.514664  0.304412"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation der Modelle\n",
    "pt.Experiment(\n",
    "    list(retrieval_models_nltk.values()),\n",
    "    topics_nltk,\n",
    "    pt_dataset.get_qrels(),\n",
    "    [\"ndcg_cut.10\", \"recip_rank\", \"recall_100\", \"P_10\"],\n",
    "    names=list(retrieval_models_nltk.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ndcg_cut.10</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>recall_100</th>\n",
       "      <th>P_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L_S_T_XSqrA_M</td>\n",
       "      <td>0.412752</td>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.543502</td>\n",
       "      <td>0.355882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L_S_T_BM25</td>\n",
       "      <td>0.340062</td>\n",
       "      <td>0.568778</td>\n",
       "      <td>0.533040</td>\n",
       "      <td>0.297059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L_S_T_DPH</td>\n",
       "      <td>0.396113</td>\n",
       "      <td>0.623806</td>\n",
       "      <td>0.539705</td>\n",
       "      <td>0.336765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L_S_C_XSqrA_M</td>\n",
       "      <td>0.406269</td>\n",
       "      <td>0.662312</td>\n",
       "      <td>0.548509</td>\n",
       "      <td>0.341176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_S_C_BM25</td>\n",
       "      <td>0.326777</td>\n",
       "      <td>0.572283</td>\n",
       "      <td>0.532044</td>\n",
       "      <td>0.279412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L_S_C_DPH</td>\n",
       "      <td>0.389887</td>\n",
       "      <td>0.638468</td>\n",
       "      <td>0.539980</td>\n",
       "      <td>0.329412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L_S_N_XSqrA_M</td>\n",
       "      <td>0.397748</td>\n",
       "      <td>0.663278</td>\n",
       "      <td>0.538604</td>\n",
       "      <td>0.333824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L_S_N_BM25</td>\n",
       "      <td>0.310113</td>\n",
       "      <td>0.550603</td>\n",
       "      <td>0.512335</td>\n",
       "      <td>0.266176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L_S_N_DPH</td>\n",
       "      <td>0.374509</td>\n",
       "      <td>0.631454</td>\n",
       "      <td>0.530680</td>\n",
       "      <td>0.311765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  ndcg_cut.10  recip_rank  recall_100      P_10\n",
       "0  L_S_T_XSqrA_M     0.412752    0.629893    0.543502  0.355882\n",
       "1     L_S_T_BM25     0.340062    0.568778    0.533040  0.297059\n",
       "2      L_S_T_DPH     0.396113    0.623806    0.539705  0.336765\n",
       "3  L_S_C_XSqrA_M     0.406269    0.662312    0.548509  0.341176\n",
       "4     L_S_C_BM25     0.326777    0.572283    0.532044  0.279412\n",
       "5      L_S_C_DPH     0.389887    0.638468    0.539980  0.329412\n",
       "6  L_S_N_XSqrA_M     0.397748    0.663278    0.538604  0.333824\n",
       "7     L_S_N_BM25     0.310113    0.550603    0.512335  0.266176\n",
       "8      L_S_N_DPH     0.374509    0.631454    0.530680  0.311765"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation der Modelle\n",
    "pt.Experiment(\n",
    "    list(retrieval_models_spacy.values()),\n",
    "    topics_spacy,\n",
    "    pt_dataset.get_qrels(),\n",
    "    [\"ndcg_cut.10\", \"recip_rank\", \"recall_100\", \"P_10\"],\n",
    "    names=list(retrieval_models_spacy.keys())\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
